{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT REQUIRED MODULES\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "from shapely.geometry import box\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of datacubes intersecting the study region is: 2\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE OUTPUT DIRECTORY TO WHICH THE 6-DAY PAIRS SHOULD BE DOWNLOADED\n",
    "output_dir = 'R:/KOGE_BUGT/ITS_LIVE_6_DAY'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# DEFINE THE STUDY REGION FOR THE 6-DAY PAIRS (KOGE BUGT C)\n",
    "bounds = 162212, -2741663, 210963, -2712025 # xmin, ymin, xmax, ymax\n",
    "aoi_3413 = gpd.GeoDataFrame(geometry=[box(*(bounds))], crs=3413)\n",
    "\n",
    "# SEARCH AND PRINT THE NUMBER OF DATACUBES INTERSECTING THE STUDY REGION\n",
    "url = 'https://its-live-data.s3.amazonaws.com/datacubes/catalog_v02.json'\n",
    "response = urlopen(url)\n",
    "data_json = json.loads(response.read())\n",
    "df = pd.read_json('https://its-live-data.s3.amazonaws.com/datacubes/catalog_v02.json')\n",
    "gdf = gpd.GeoDataFrame.from_features(df[\"features\"])\n",
    "gdf = gdf[gdf['epsg']==3413]\n",
    "gdf = gdf.set_crs(4326).to_crs(3413)\n",
    "gdf_intsct = gdf[gdf.intersects(aoi_3413.geometry.values[0])]\n",
    "number_of_datacubes = len(gdf_intsct)\n",
    "print('The number of datacubes intersecting the study region is:', number_of_datacubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset from tile ITS_LIVE_vel_EPSG3413_G0120_X150000_Y-2750000\n",
      "Appending to list.\n",
      "Preparing dataset from tile ITS_LIVE_vel_EPSG3413_G0120_X250000_Y-2750000\n",
      "Appending to list.\n"
     ]
    }
   ],
   "source": [
    "# PREPARE DATA STRUCTURES TO PROCESS THE ZARR FILES\n",
    "url_zarr_list = gdf_intsct.zarr_url.values\n",
    "xds_list = []\n",
    "fn_list = []\n",
    "filename_counts = {}\n",
    "\n",
    "# ITERATE THROUGH THE LIST OF ZARR FILE, EXTRACT INFO AND PROCESS USING XARRAY \n",
    "for url_zarr in url_zarr_list:\n",
    "    filename = os.path.basename(url_zarr).split('.')[0]\n",
    "    fn_list.append(filename)\n",
    "    print(f'Preparing dataset from tile {filename}')\n",
    "    xds = xr.open_zarr(url_zarr) \n",
    "    if filename in filename_counts: \n",
    "        filename_counts[filename] += 1\n",
    "        identifier = f'T{filename_counts[filename]}' \n",
    "    else:\n",
    "        filename_counts[filename] = 1\n",
    "        identifier = ''  \n",
    "    filename = f'{filename}{identifier}'\n",
    "    xds = xds[['satellite_img1','satellite_img2','acquisition_date_img1','acquisition_date_img2', 'date_dt','v']]\n",
    "    xds = xds.rio.write_crs('epsg:3413')\n",
    "    xds = xds.rio.clip(aoi_3413.geometry) # Clip to the study region\n",
    "    xds = xds.where(((xds.date_dt.dt.days == 6) | (xds.date_dt.dt.days == 12)).compute(), drop=True) # Include 6-day and 12-day pairs\n",
    "    xds = xds.where(((xds.satellite_img1 == '1A') | (xds.satellite_img1 == '1B')).compute(), drop=True)\n",
    "    var_obj_list = ['satellite_img1', 'satellite_img2']\n",
    "    for var in var_obj_list:\n",
    "        xds[var] = xds[var].astype('str')\n",
    "    xds = xds.chunk()\n",
    "    xds_list.append(xds)\n",
    "    print(f'Appending to list.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing dataset ITS_LIVE_vel_EPSG3413_G0120_X150000_Y-2750000. This may take a while...\n",
      "Computed dataset. Saving images...\n",
      "Saved images.\n",
      "Computing dataset ITS_LIVE_vel_EPSG3413_G0120_X250000_Y-2750000. This may take a while...\n",
      "Computed dataset. Saving images...\n",
      "Saved images.\n"
     ]
    }
   ],
   "source": [
    "# LOOP THROUGH THE XDS_LIST AND FN_LIST TOGETHER, SAVING THE GEOTIFF IMAGES\n",
    "for xds, filename in zip(xds_list, fn_list):\n",
    "    if not os.path.exists(f'{output_dir}/{filename}'):\n",
    "        os.mkdir(f'{output_dir}/{filename}')\n",
    "    print(f'Computing dataset {filename}. This may take a while...')\n",
    "    with xds.compute() as xds:\n",
    "        print(f'Computed dataset. Saving images...')\n",
    "        filename_counts = {}\n",
    "        for _, x in xds.groupby('mid_date'):\n",
    "            outname = f'{x.acquisition_date_img1.dt.date.values[0]}_{x.acquisition_date_img2.dt.date.values[0]}_S{x.satellite_img1.values[0]}_S{x.satellite_img2.values[0]}'\n",
    "            if outname in filename_counts:\n",
    "                filename_counts[outname] += 1\n",
    "                identifier = f'_T{filename_counts[outname]}'   \n",
    "            else:\n",
    "                filename_counts[outname] = 1\n",
    "                identifier = '' \n",
    "            if identifier == '_T1':\n",
    "                identifier = ''\n",
    "            outfpath = f'{output_dir}/{filename}/{outname}{identifier}.tif'\n",
    "            x.v.rio.to_raster(outfpath, compress='ZSTD', predictor=3, zlevel=1)\n",
    "        print('Saved images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deletion of tiff files outside the desired study period complete.\n"
     ]
    }
   ],
   "source": [
    "# DELETE ANY FILES WHICH HAVE A 'MID-DATE' OUTSIDE OF THE DESIRED DATE RANGE (2016-2024)\n",
    "start_date = datetime(2016, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "filtered_files = []\n",
    "directory = 'R:/KOGE_BUGT/ITS_LIVE_6_DAY/ITS_LIVE_vel_EPSG3413_G0120_X250000_Y-2750000'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.tif'):\n",
    "        parts = filename.split('_')\n",
    "        file_end_date = datetime.strptime(parts[1], '%Y-%m-%d')\n",
    "        if file_end_date < start_date or file_end_date > end_date:\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            os.remove(file_path)\n",
    "\n",
    "print(\"Deletion of tiff files outside the desired study period complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velocity_download",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
